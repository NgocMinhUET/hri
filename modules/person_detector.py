"""
Person Detector - Ph√°t hi·ªán ng∆∞·ªùi trong v√πng t∆∞∆°ng t√°c
S·ª≠ d·ª•ng YOLOv8 tr√™n camera IMX477
"""
import cv2
import numpy as np
from ultralytics import YOLO
import time
from typing import Optional, Tuple
from utils.logger import setup_logger
from utils.config_loader import get_config

class PersonDetector:
    """Ph√°t hi·ªán ng∆∞·ªùi xu·∫•t hi·ªán trong v√πng t∆∞∆°ng t√°c"""
    
    def __init__(self, config=None):
        """
        Args:
            config: ConfigLoader instance
        """
        self.config = config or get_config()
        self.logger = setup_logger("PersonDetector")
        
        # Load c·∫•u h√¨nh
        self.camera_id = self.config.get('camera.device_id', 0)
        self.resolution = (
            self.config.get('camera.resolution.width', 640),
            self.config.get('camera.resolution.height', 480)
        )
        self.fps = self.config.get('camera.fps', 30)
        
        # Detection zone
        self.zone_x = self.config.get('camera.detection_zone.x', 160)
        self.zone_y = self.config.get('camera.detection_zone.y', 120)
        self.zone_w = self.config.get('camera.detection_zone.width', 320)
        self.zone_h = self.config.get('camera.detection_zone.height', 240)
        
        # Person detection settings
        model_path = self.config.get('person_detection.model', 'yolov8n.pt')
        self.confidence_threshold = self.config.get('person_detection.confidence_threshold', 0.5)
        self.cooldown = self.config.get('person_detection.cooldown_seconds', 3)
        
        # Load YOLO model
        self.logger.info(f"ƒêang load model {model_path}...")
        self.model = YOLO(model_path)
        
        # Camera
        self.cap = None
        self.last_detection_time = 0
        
        self.logger.info("PersonDetector ƒë√£ s·∫µn s√†ng!")
    
    def start_camera(self):
        """Kh·ªüi ƒë·ªông camera"""
        if self.cap is not None:
            self.logger.warning("Camera ƒë√£ ƒë∆∞·ª£c kh·ªüi ƒë·ªông r·ªìi!")
            return
        
        self.logger.info(f"ƒêang kh·ªüi ƒë·ªông camera {self.camera_id}...")
        self.cap = cv2.VideoCapture(self.camera_id)
        
        if not self.cap.isOpened():
            self.logger.error(f"Kh√¥ng th·ªÉ m·ªü camera {self.camera_id}")
            self.logger.error("H√£y ch·∫°y: python test_camera.py ƒë·ªÉ t√¨m device ID ƒë√∫ng")
            raise RuntimeError(f"Kh√¥ng th·ªÉ m·ªü camera {self.camera_id}")
        
        # Set resolution (sau khi m·ªü th√†nh c√¥ng)
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.resolution[0])
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.resolution[1])
        self.cap.set(cv2.CAP_PROP_FPS, self.fps)
        
        # Ki·ªÉm tra th·ª±c t·∫ø resolution ƒë√£ set
        actual_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        actual_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        actual_fps = self.cap.get(cv2.CAP_PROP_FPS)
        
        self.logger.info(f"Camera ƒë√£ s·∫µn s√†ng! Resolution: {actual_width}x{actual_height} @ {actual_fps:.1f}fps")
        
        # Test ƒë·ªçc frame ƒë·∫ßu ti√™n
        ret, test_frame = self.cap.read()
        if not ret:
            self.logger.warning("C·∫£nh b√°o: Camera m·ªü ƒë∆∞·ª£c nh∆∞ng ch∆∞a ƒë·ªçc ƒë∆∞·ª£c frame. ƒê·ª£i v√†i gi√¢y...")
            import time
            time.sleep(2)
            ret, test_frame = self.cap.read()
            if ret:
                self.logger.info("‚úÖ Camera ƒë√£ s·∫µn s√†ng sau khi ƒë·ª£i!")
            else:
                self.logger.error("‚ùå V·∫´n kh√¥ng ƒë·ªçc ƒë∆∞·ª£c frame. Ki·ªÉm tra camera!")
    
    def stop_camera(self):
        """D·ª´ng camera"""
        if self.cap is not None:
            self.cap.release()
            self.cap = None
            self.logger.info("ƒê√£ d·ª´ng camera.")
    
    def detect_person_in_zone(self) -> bool:
        """
        Ki·ªÉm tra xem c√≥ ng∆∞·ªùi trong v√πng detection kh√¥ng
        
        Returns:
            True n·∫øu ph√°t hi·ªán ng∆∞·ªùi trong zone
        """
        if self.cap is None:
            self.logger.error("Camera ch∆∞a ƒë∆∞·ª£c kh·ªüi ƒë·ªông!")
            return False
        
        # Ki·ªÉm tra cooldown
        current_time = time.time()
        if current_time - self.last_detection_time < self.cooldown:
            return False
        
        # ƒê·ªçc frame
        ret, frame = self.cap.read()
        if not ret:
            self.logger.error(f"Kh√¥ng th·ªÉ ƒë·ªçc frame t·ª´ camera {self.camera_id}!")
            self.logger.error("C√≥ th·ªÉ do:")
            self.logger.error("  1. Camera device ID sai (ki·ªÉm tra: python test_camera.py)")
            self.logger.error("  2. Camera ƒëang b·ªã process kh√°c s·ª≠ d·ª•ng")
            self.logger.error("  3. Camera c·∫ßn th·ªùi gian kh·ªüi ƒë·ªông (th·ª≠ ƒë·ª£i v√†i gi√¢y)")
            self.logger.error("  4. Permissions (th·ª≠: sudo chmod 666 /dev/video*)")
            return False
        
        # Run detection
        results = self.model(frame, verbose=False)
        
        # Ki·ªÉm tra t·ª´ng detection
        for result in results:
            boxes = result.boxes
            for box in boxes:
                # Class 0 l√† 'person' trong COCO dataset
                if int(box.cls[0]) == 0 and float(box.conf[0]) >= self.confidence_threshold:
                    # L·∫•y bounding box
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    
                    # T√≠nh center c·ªßa bounding box
                    center_x = (x1 + x2) / 2
                    center_y = (y1 + y2) / 2
                    
                    # Ki·ªÉm tra xem center c√≥ trong zone kh√¥ng
                    if (self.zone_x <= center_x <= self.zone_x + self.zone_w and
                        self.zone_y <= center_y <= self.zone_y + self.zone_h):
                        
                        self.logger.info(f"‚úÖ Ph√°t hi·ªán ng∆∞·ªùi trong zone! (confidence: {box.conf[0]:.2f})")
                        self.last_detection_time = current_time
                        return True
        
        return False
    
    def get_frame_with_visualization(self) -> Optional[np.ndarray]:
        """
        L·∫•y frame v·ªõi visualization (boxes v√† zone)
        D√πng cho debug/display
        
        Returns:
            Frame v·ªõi visualization ho·∫∑c None
        """
        if self.cap is None:
            return None
        
        ret, frame = self.cap.read()
        if not ret:
            return None
        
        # V·∫Ω detection zone
        cv2.rectangle(
            frame,
            (self.zone_x, self.zone_y),
            (self.zone_x + self.zone_w, self.zone_y + self.zone_h),
            (0, 255, 0), 2
        )
        
        # Run detection v√† v·∫Ω boxes
        results = self.model(frame, verbose=False)
        
        for result in results:
            boxes = result.boxes
            for box in boxes:
                if int(box.cls[0]) == 0:  # person
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    conf = float(box.conf[0])
                    
                    # M√†u: xanh n·∫øu trong zone, ƒë·ªè n·∫øu ngo√†i zone
                    center_x = (x1 + x2) / 2
                    center_y = (y1 + y2) / 2
                    in_zone = (self.zone_x <= center_x <= self.zone_x + self.zone_w and
                              self.zone_y <= center_y <= self.zone_y + self.zone_h)
                    
                    color = (0, 255, 0) if in_zone else (0, 0, 255)
                    
                    # V·∫Ω box
                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
                    cv2.putText(frame, f"Person {conf:.2f}", (int(x1), int(y1)-10),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        return frame
    
    def run_detection_loop(self, callback=None, show_preview=True):
        """
        Ch·∫°y detection loop li√™n t·ª•c
        
        Args:
            callback: H√†m ƒë∆∞·ª£c g·ªçi khi ph√°t hi·ªán ng∆∞·ªùi (optional)
            show_preview: Hi·ªÉn th·ªã preview window (default: True)
        """
        self.logger.info("B·∫Øt ƒë·∫ßu detection loop...")
        
        try:
            while True:
                # Ph√°t hi·ªán ng∆∞·ªùi
                detected = self.detect_person_in_zone()
                
                if detected and callback:
                    callback()
                
                # Hi·ªÉn th·ªã preview
                if show_preview:
                    frame = self.get_frame_with_visualization()
                    if frame is not None:
                        cv2.imshow('Person Detection', frame)
                    
                    # Nh·∫•n 'q' ƒë·ªÉ tho√°t
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        break
                else:
                    time.sleep(0.1)
                    
        except KeyboardInterrupt:
            self.logger.info("D·ª´ng detection loop.")
        finally:
            if show_preview:
                cv2.destroyAllWindows()
    
    def __del__(self):
        """Cleanup"""
        self.stop_camera()

# Test standalone
if __name__ == "__main__":
    detector = PersonDetector()
    detector.start_camera()
    
    def on_person_detected():
        print("üö∂ C√≥ ng∆∞·ªùi trong v√πng t∆∞∆°ng t√°c!")
    
    detector.run_detection_loop(callback=on_person_detected, show_preview=True)

